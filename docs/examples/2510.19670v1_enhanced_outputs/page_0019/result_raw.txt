<|ref|>text<|/ref|><|det|>[[75, 60, 492, 905]]<|/det|>
[55] Jianchun Liu, Hongli Xu, Yang Xu, Zhenguo Ma, Zhiyuan Wang, Chen Qian, and He Huang. Communication- efficient asynchronous federated learning in resource- constrained edge computing. Computer Networks, 199:108429, 2021. [56] Zhiyuan Wang, Hongli Xu, Jianchun Liu, He Huang, Chunming Qiao, and Yangming Zhao. Resource- efficient federated learning with hierarchical aggregation in edge computing. In IEEE INFOCOM 2021- IEEE conference on computer communications, pages 1- 10. IEEE, 2021. [57] Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. arXiv preprint arXiv:2304.08485, 2023. [58] Zechun Liu, Changsheng Zhao, Forrest Iandola, Chen Lai, Yuandong Tian, Igor Fedorov, Yunyang Xiong, Ernie Chang, Yangyang Shi, Raghuraman Krishnamoorthi, Liangzhen Lai, and Vikas Chandra. Mobilellm: Optimizing sub- billion parameter language models for on- device use cases. arXiv preprint arXiv:2402.14905, 2024. [59] Feng- Qi Cui, Anyang Tong, Jinyang Huang, Jie Zhang, Dan Guo, Zhi Liu, and Meng Wang. Learning from heterogeneity: Generalizing dynamic facial expression recognition via distributionally robust optimization. In Proceedings of the 33nd ACM International Conference on Multimedia, MM '25, New York, NY, USA, 2025. Association for Computing Machinery.[60] Zhiwei Yao, Jianchun Liu, Hongli Xu, Lun Wang, Chen Qian, and Yunming Liao. Ferrari: A personalized federated learning framework for heterogeneous edge clients. IEEE Transactions on Mobile Computing, 23(10):10031- 10045, 2024. [61] Jiaming Yan, Jianchun Liu, Hongli Xu, Zhiyuan Wang, and Chunming Qiao. Peaches: Personalized federated learning with neural architecture search in edge computing. IEEE Transactions on Mobile Computing, 23(11):10296- 10312, 2024. [62] Rukuo Li, Jianchun Liu, Hongli Xu, and Liusheng Huang. Fedquad: Adaptive layer- wise lora deployment and activation quantization for federated fine- tuning. arXiv preprint arXiv:2506.01001, 2025. [63] Jianchun Liu, Jiaming Yan, Ji Qi, Hongli Xu, Shilong Wang, Chunming Qiao, and Liusheng Huang. Adaptive local update and neural composition for accelerating federated learning in heterogeneous edge networks. IEEE Transactions on Networking, 2025. [64] Jianchun Liu, Jiaming Yan, Hongli Xu, Lun Wang, Zhiyuan Wang, Jinyang Huang, and Chunming Qiao. Accelerating decentralized federated learning with probabilistic communication in heterogeneous edge computing. IEEE Transactions on Networking, 2025. [65] Jiaming Yan, Jianchun Liu, Hongli Xu, and Liusheng Huang. Accelerating mixture- of- expert inference with adaptive expert split mechanism. arXiv preprint arXiv:2509.08342, 2025. [66] Shilong Wang, Jianchun Liu, Hongli Xu, Chenxia Tang, Qianpiao Ma, and Liusheng Huang. Towards communication- efficient decentralized federated graph learning over non- iid data. arXiv preprint arXiv:2509.08409, 2025. [67] Chenxia Tang, Jianchun Liu, Hongli Xu, and Liusheng Huang. Top- n: Eliminating noise in logit space for robust token sampling of llm. In Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 10758- 10774, 2025. [68] Yujia Huo, Jianchun Liu, Hongli Xu, Zhenguo Ma, Shilong Wang, and Liusheng Huang. Mitigating catastrophic forgetting with adaptive transformer block expansion in federated fine- tuning. arXiv preprint arXiv:2506.05977, 2025. [69] Luyao Gao, Jianchun Liu, Hongli Xu, Sun Xu, Qianpiao Ma, and Liusheng Huang. Accelerating end- cloud collaborative inference via near bubble- free pipeline optimization. In IEEE INFOCOM 2025- IEEE Conference on Computer Communications, pages 1- 10. IEEE, 2025. [70] Akrit Mudvari, Yuang Jiang, and Leandros Tassiulas. Splitllm: Efficient collaborative inference of large language models with split inference. arXiv preprint arXiv:2410.10759, 2024. [71] Foteini Strati, Sara McAllister, Amar Phanishayee, Jakub Tarnawski, and Ana Klimovic. DejaVu: KV- cache streaming for fast, fault- tolerant generative LLM serving. In Proceedings of the 41st International Conference on Machine Learning, PMLR, pages 46745- 46771, 2024. [72] Yuhui Li, Fangyun Wei, Chao Zhang, and Hongyang Zhang. Eagle: Speculative sampling requires rethinking feature uncertainty. arXiv preprint arXiv:2401.15077, 2024. [73] Yuhong Li, Yingbing Huang, Bowen Yang, Bharat Venkitesh, Acyr Locatelli, Hanchen Ye, Tianle Cai, Patrick Lewis, and Deming Chen. Snapkv: Llm knows what you are looking for before generation. arXiv preprint arXiv:2404.14469, 2024.  

<|ref|>text<|/ref|><|det|>[[504, 64, 920, 301]]<|/det|>
[74] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen- Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. Lora: Low- rank adaptation of large language models. arXiv preprint arXiv:2106.09685, 2021. [75] Jianchun Liu, Jun Liu, Hongli Xu, Yunming Liao, Zhiwei Yao, Min Chen, and Chen Qian. Enhancing semi- supervised federated learning with progressive training in heterogeneous edge computing. IEEE Transactions on Mobile Computing, 2024. [76] Jun Liu, Jianchun Liu, Hongli Xu, Yunming Liao, Zhiyuan Wang, and Qianpiao Ma. Yoga: Adaptive layer- wise model aggregation for decentralized federated learning. IEEE/ACM Transactions on Networking, 32(2):1768- 1780, 2023. [77] Jianchun Liu, Qingmin Zeng, Hongli Xu, Yang Xu, Zhiyuan Wang, and He Huang. Adaptive block- wise regularization and knowledge distillation for enhancing federated learning. IEEE/ACM Transactions on Networking, 32(1):791- 805, 2023. [78] Ruiyang Qin, Zheyu Yan, Dewen Zeng, Zhengze Jia, Dancheng Liu, Jianbo Liu, Zhi Zheng, Ningyuan Cao, Kai Ni, Jinjun Xiong, and Yiyu Shi. Robust implementation of retrieval- augmented generation on edge- based computing- in- memory architectures. arXiv preprint arXiv:2405.04700, 2024.