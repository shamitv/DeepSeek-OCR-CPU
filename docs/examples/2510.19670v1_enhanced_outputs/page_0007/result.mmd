
### C. Edge-RAG: Local Grounding and Consistency  


a) Local corpora and indices.: Each edge node maintains a private corpus: site policies (e.g., fall-response SOPs), device manuals, location maps, and short textual notes distilled from prior cases. We build a hybrid index combining a vector store (for dense semantic search) and a lightweight inverted index (for keyword/BM25). The query \(q\) is formed from \((Z\) a small set of salient \(h\) 's, and structured fields like room ID and last seen user).  


b) Hybrid retrieval score and cross-piece consistency.: The final ranking score blends dense similarity, sparse matching, and a consistency prior that penalizes mutually contradictory snippets:  


\[s(d\mid q) = \lambda \cdot \cos \big(f(q),f(d)\big) + (1 - \lambda)\cdot \mathrm{BM25}(q,d) + \kappa \cdot \Gamma (d\mid C) \quad (3)\]  


Symbols: \(f(\cdot)\) is an embedding function; \(\cos (\cdot ,\cdot)\) cosine similarity; BM25 sparse score; \(\Gamma\) consistency with current candidate set \(C\) . \(\lambda ,\kappa \in [0,1]\)  


We operationalize \(\Gamma\) via pairwise entailment scores between candidate snippets (obtained from a tiny on- edge NLI head) and prefer sets that are jointly consistent. The top- \(k\) snippets ( \(k\leq 5\) on memory- constrained devices) are slotted into a structured prompt with fields [Setting], [Entities], [Evidence], and [Policy].  


### D. PromptRouter: Uncertainty- and Cost-Aware Cooperation  


a) Uncertainty estimates.: To avoid hallucinated explanations and wasted escalations, we compute an uncertainty score \(u\) that aggregates both sensory and language-side proxies. On the sensory side, we use MC-dropout on the classification head; on the language side, we use predictive entropy over candidate rationales from a tiny draft head. A single scalar \(u\) is obtained by min-max normalization and convex combination:  


\[u = \eta \cdot \mathsf{H}\big(\hat{y}\mid X_{1:T}\big) + (1 - \eta)\cdot \mathsf{H}\big(\hat{e}\mid Z,\mathcal{D}\big) \quad (4)\]  


Symbols: \(\mathsf{H}(\cdot)\) Shannon entropy; \(\hat{y}\) class posteriors from SenseFusion; \(\hat{e}\) rationale/summary posteriors from a small draft generator; \(\eta \in\) [0, 1] mixing weight; \(\mathcal{D}\) retrieved docs.  


b) Explicit cost model.: We estimate a per-decision cost \(C\) that reflects end-to-end latency, energy, token budget (for cloud billing and time), and a conservative privacy risk proxy (share of raw vs. semantic data):  


\[C = \alpha \cdot \hat{\mathsf{lat}} +\beta \cdot \mathsf{energy} + \gamma \cdot \mathsf{tokens} + \delta \cdot \mathsf{risk} \quad (5)\]  


Symbols: \(\hat{\mathsf{lat}}\) predicted latency; \(\mathsf{energy}\) estimated energy per decision; tokens expected prompt+generation tokens; risk privacy risk score; \(\alpha ,\beta ,\gamma ,\delta \geq 0\)  


We maintain parametric predictors for latency/energy using online regression with features (model quantization level, batch occupancy, code length \(K\) , retrieved \(k\) , link bandwidth). Risk is a rule- based score that rises when any raw waveform is requested (normally disabled) or when named entities/personal data might cross boundaries; in our default profile only \(Z\) and redacted metadata are ever transmitted.  


c) Policy.: The router chooses among three actions: EDGE-ONLY (generate locally with the tiny LLM), EDGE+RAG (retrieve then generate locally), and ESCALATE (send a compact prompt to the cloud LLM). We minimize a one-step risk that trades task loss \(\mathbb{E}[\ell ]\) , cost \(C\) , and uncertainty \(u\) :  


### E. Prompt Construction and Redaction  


The prompt template is structured to be deterministic and cache- friendly. The header captures Context (site ID, time window, device health), then a Semantics block with the code sequence \(Z\) and salient latent tokens (few \(h\) 's with PCA compression), then Evidence (retrieved snippets \(\mathcal{D}\) ), and finally Task (explain/advise/abstain). Redaction removes personal names, exact coordinates, or raw waveform hashes. If the risk rule flags a potential leak (e.g., an excerpt contains a personal identifier not whitelisted), the router degrades to abstracted evidence (e.g., "Resident A in Room 12").  


### F. Training Objectives and Curriculum  


a) Stage I: Self-supervised modality pretraining.: Each \(\phi_{m}\) is trained on large unlabeled windows with masked prediction and temporal contrast, e.g., TS-TCC-style tasks. We freeze stem layers to stabilize later alignment.  


b) Stage II: Cross-modal alignment and VQ code learning.: We jointly optimize \(\mathcal{L}_{\mathrm{align}}\) (Eq. 1) and \(\mathcal{L}_{\mathrm{VQ}}\) (Eq. 2) with a small supervised head where labels exist (gestures, respiration phases). VQ codebooks are initialized by \(k\) -means on pooled \(u_{k}\) to avoid code collapse; EMA updates stabilize code vectors.  


c) Stage III: Instruction tuning for explanation.: A compact on-edge LLM (e.g., 1.8-3B params, 4/8-bit) is tuned with structured inputs \((Z,\mathcal{D})\mapsto E\) using instruction-style pairs synthesized from policies and curated exemplars. We also train a micro "draft" head to output short rationales for uncertainty estimation. For cloud LLMs, we only tune prompt formats.  


d) Stage IV: Router calibration.: We calibrate predictive latency/energy models by sweeping quantization levels, concurrent sessions, and link bandwidths on the target hardware. The task-loss proxy \(\mathbb{E}[\ell \mid a]\) is fitted from validation rollouts that pair \((u,C)\) with achieved F1 and explanation quality scores (BERTScore and human ratings). Thresholds \((\theta_{a})\) are chosen by minimizing expected regret on a held-out day.  


### G. Online Personalization (Edge and Federated)  


Site- specific drift (furniture moves, channel changes, seasonal patterns) and user- specific behavior motivate continual adaptation. We expose two knobs:  


(i) Local refinement. A tiny adapter (LoRA with rank 4-16) sits in each \(\phi_{m}\) and in the cross-modal attention. We periodically fine-tune adapters on pseudo-labeled windows (high-confidence predictions) with a replay buffer and entropy regularization to avoid drift. Quantized fine-tuning (int8/4- weight) keeps memory within edge constraints.  


(ii) Federated rounds. When allowed, we join periodic FL rounds that aggregate adapter deltas and codebook nudges across sites. Communication is stratified: codebook updates